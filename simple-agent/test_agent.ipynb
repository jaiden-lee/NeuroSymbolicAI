{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaide\\Documents\\CodingProjects\\NeuroSymbolicAI\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 24 key-value pairs and 195 tensors from C:\\Users\\jaide\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct-gguf\\snapshots\\c80d904a71b99a3eaeb8d3dbf164166384c09dc3\\Phi-3-mini-4k-instruct-q4.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = phi3\n",
      "llama_model_loader: - kv   1:                               general.name str              = Phi3\n",
      "llama_model_loader: - kv   2:                        phi3.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                      phi3.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   4:                   phi3.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   5:                           phi3.block_count u32              = 32\n",
      "llama_model_loader: - kv   6:                  phi3.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:               phi3.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   8:      phi3.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv   9:                  phi3.rope.dimension_count u32              = 96\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32064]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32064]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 32000\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:   81 tensors\n",
      "llama_model_loader: - type q5_K:   32 tensors\n",
      "llama_model_loader: - type q6_K:   17 tensors\n",
      "llm_load_vocab: special tokens cache size = 323\n",
      "llm_load_vocab: token to piece cache size = 0.1687 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = phi3\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32064\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 3072\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 96\n",
      "llm_load_print_meta: n_embd_head_k    = 96\n",
      "llm_load_print_meta: n_embd_head_v    = 96\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 3072\n",
      "llm_load_print_meta: n_embd_v_gqa     = 3072\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 8192\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 3B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 3.82 B\n",
      "llm_load_print_meta: model size       = 2.23 GiB (5.01 BPW) \n",
      "llm_load_print_meta: general.name     = Phi3\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOT token        = 32007 '<|end|>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors:        CPU buffer size =  2281.66 MiB\n",
      "...........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 32000\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size = 12000.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 12000.00 MiB, K (f16): 6000.00 MiB, V (f16): 6000.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =  2098.51 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.ggml.model': 'llama', 'phi3.feed_forward_length': '8192', 'general.name': 'Phi3', 'general.architecture': 'phi3', 'phi3.context_length': '4096', 'phi3.attention.head_count_kv': '32', 'phi3.embedding_length': '3072', 'phi3.block_count': '32', 'phi3.attention.head_count': '32', 'phi3.attention.layer_norm_rms_epsilon': '0.000010', 'phi3.rope.dimension_count': '96', 'tokenizer.ggml.eos_token_id': '32000', 'general.file_type': '15', 'tokenizer.ggml.pre': 'default', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.padding_token_id': '32000', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\\n' + message['content'] + '<|end|>' + '\\n' + '<|assistant|>' + '\\n'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\\n'}}{% endif %}{% endfor %}\"}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\n",
      "' + message['content'] + '<|end|>' + '\n",
      "' + '<|assistant|>' + '\n",
      "'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\n",
      "'}}{% endif %}{% endfor %}\n",
      "Using chat eos_token: <|endoftext|>\n",
      "Using chat bos_token: <s>\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(\"https://arxiv.org/html/2306.05685v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   19243.71 ms\n",
      "llama_print_timings:      sample time =      14.86 ms /    42 runs   (    0.35 ms per token,  2826.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22391.30 ms /   599 tokens (   37.38 ms per token,    26.75 tokens per second)\n",
      "llama_print_timings:        eval time =    4331.30 ms /    41 runs   (  105.64 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =   26809.64 ms /   640 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thought: I am presented with a straightforward word problem where I need to calculate the total number of apples Bob has after his purchase.\n",
      "Action: calculator: 3+2\n",
      "\n",
      "calculator\n",
      "3+2\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   19243.71 ms\n",
      "llama_print_timings:      sample time =       3.65 ms /    13 runs   (    0.28 ms per token,  3566.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6122.82 ms /    47 tokens (  130.27 ms per token,     7.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1446.61 ms /    12 runs   (  120.55 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =    7589.68 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Answer: Bob now has 5 apples.\n",
      "FOUND ANSWER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   19243.71 ms\n",
      "llama_print_timings:      sample time =      10.39 ms /    26 runs   (    0.40 ms per token,  2502.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17308.92 ms /   380 tokens (   45.55 ms per token,    21.95 tokens per second)\n",
      "llama_print_timings:        eval time =    2757.81 ms /    25 runs   (  110.31 ms per token,     9.07 tokens per second)\n",
      "llama_print_timings:       total time =   20110.10 ms /   405 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: The previous answer is correct and accurately answers the question provided.\n",
      "Score: 10\n",
      "\n",
      "\n",
      "\n",
      "Answer: Bob now has 5 apples.\n"
     ]
    }
   ],
   "source": [
    "output = agent.query(\"Bob has 3 apples. He buys 2. How many does he have now?\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   19243.71 ms\n",
      "llama_print_timings:      sample time =       9.44 ms /    42 runs   (    0.22 ms per token,  4450.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15738.76 ms /   583 tokens (   27.00 ms per token,    37.04 tokens per second)\n",
      "llama_print_timings:        eval time =    3817.07 ms /    41 runs   (   93.10 ms per token,    10.74 tokens per second)\n",
      "llama_print_timings:       total time =   19611.77 ms /   624 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thought: I need information about both Chatbot Arena and MTBench in order to find out the differences.\n",
      "Action: retrieveDocuments: What is Chatbot Arena?\n",
      "\n",
      "retrieveDocuments\n",
      "What is Chatbot Arena?\n",
      "[Chatbot Arena.\n",
      "We randomly sample 3K single-turn votes from 30K arena data, which covers models including GPT-4, GPT-3.5, Claude, Vicuna-7B/13B, Koala-13B [16], Alpaca-13B, LLaMA-13B, and Dolly-12B. We use two kinds of judges: LLM judges and collected crowd judges (2114 unique IPs)., In this paper, we propose LLM-as-a-judge for chatbot evaluation and systematically examine its efficacy using human preference data from 58 experts on MT-bench, as well as thousands of crowd-users on Chatbot Arena.\n",
      "Our results reveal that strong LLMs can achieve an agreement rate of over 80%, on par with the level of agreement among human experts, establishing a foundation for an LLM-based evaluation framework., Title: Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena, We study the agreement between different LLM judges and humans on MT-bench and Chatbot Arena datasets. On MT-bench, we also study the agreement among humans. MT-bench represents a small-scale study with controlled human evaluation, while Chatbot Arena represents a larger-scale study with crowdsourced human evaluation in the wild., To study this, we introduce two benchmarks with human ratings as the primary evaluation metric: MT-bench and Chatbot Arena.\n",
      "MT-bench is a series of open-ended questions that evaluate a chatbot’s multi-turn conversational and instruction-following ability – two critical elements for human preference. MT-bench is also carefully constructed to differentiate chatbots based on their core capabilities, such as reasoning and math.\n",
      "In addition, we develop Chatbot Arena, a crowdsourced platform featuring anonymous battles between chatbots in real-world scenarios – Users engage in conversations with two chatbots at the same time and rate their responses based on personal preferences.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   19243.71 ms\n",
      "llama_print_timings:      sample time =      35.20 ms /   147 runs   (    0.24 ms per token,  4176.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17159.06 ms /   520 tokens (   33.00 ms per token,    30.30 tokens per second)\n",
      "llama_print_timings:        eval time =   14603.51 ms /   146 runs   (  100.02 ms per token,    10.00 tokens per second)\n",
      "llama_print_timings:       total time =   31960.74 ms /   666 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Observation: MTBench is an evaluation benchmark for judging chatbots' multi-turn conversation abilities, distinguishing them by core capabilities like reasoning and math. Chatbot Arena, on thee other hand, uses a crowdsourced platform where users engage in real-world scenario conversations with two chatbots at once, rating their responses based on personal preferences.\n",
      "\n",
      "Thought: I now have information to understand both MTBench and Chatbot Arena. To answer the question about the difference between these two, I'll compare their evaluation methodologies.\n",
      "Action: None needed (The information required has already been obtained from retrieveDocuments)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   19243.71 ms\n",
      "llama_print_timings:      sample time =      57.41 ms /   222 runs   (    0.26 ms per token,  3866.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (-nan(ind) ms per token, -nan(ind) tokens per second)\n",
      "llama_print_timings:        eval time =   22503.39 ms /   222 runs   (  101.37 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =   22817.62 ms /   222 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Observation: MTBench is designed to evaluate multi-turn conversational and instruction-following ability of a chatbot. It has open-ended questions that focus on reasoning and math skills among other aspects, making it suitable for differentiating chatbots based on core capabilities like reasoning and math. Chatbot Arena, on theayer with 50 mm in width (2 inches), was designed to evaluate user interaction with conversational bots through real-world scenarios. It allows users to engage in conversations anonymously with different chatbots simultaneously and rate their responses based on personal preferences.\n",
      "\n",
      "Thought: I now understand the purpose of both MTBench and Chatbot Arena. The former is a tool that assesses multi-turn conversation skills, including reasoning and math, while the latter evaluates user interactions through real-world scenarios with various chatbots. To identify their differences, I need to focus on their design goals and evaluation criteria.\n",
      "Action: None needed as no further action required at this point.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   19243.71 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /    17 runs   (    0.25 ms per token,  3960.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (-nan(ind) ms per token, -nan(ind) tokens per second)\n",
      "llama_print_timings:        eval time =    1708.81 ms /    17 runs   (  100.52 ms per token,     9.95 tokens per second)\n",
      "llama_print_timings:       total time =    1727.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Action: retrieveDocuments: What is GPT-4?\n",
      "\n",
      "\n",
      "retrieveDocuments\n",
      "What is GPT-4?\n",
      "[In both tables, GPT-4 with single-answer grading matches both pairwise GPT-4 and human preferences very well.\n",
      "This means GPT-4 has a relatively stable internal rubric.\n",
      "Although it may sometimes perform slightly worse than pairwise comparison and give more tie votes, it is a more scalable method., We then perform a breakdown analysis by computing agreement on different model pairs and categories.\n",
      "We only include non-tied votes.\n",
      "In Table 7, we observe the agreement between GPT-4 and human progressively increases in line with the performance disparity of the model pairs (i.e., larger win rate difference), from 70% to nearly 100%. This suggests that GPT-4 aligns with humans better when significant performance differences exist between the models., Figure 10 (Appendix) shows an example of position bias.\n",
      "GPT-4 is tasked to evaluate two responses from GPT-3.5 and Vicuna-13B to an open-ended question. When GPT-3.5’s answer is positioned first, GPT-4 considers GPT-3.5’s answer more detailed and superior. However, upon switching the positions of the two responses, GPT-4’s judgement flips, favoring Vicuna’s answer., Limited capability in grading math and reasoning questions.\n",
      "LLMs are known to have limited math and reasoning capability [10], which results in its failure of grading such questions because they do not know the correct answers.\n",
      "However, what is more intriguing is that it also shows limitations in grading basic math problems which it is capable of solving.\n",
      "For instance, in Figure 12 (Appendix), we present an example of an elementary math question in which GPT-4 makes an incorrect judgment.\n",
      "It’s worth noting that although GPT-4 can solve the problem (when asked separately), it was misled by the provided answers, ultimately resulting in incorrect judgment.\n",
      "This pattern can also be seen in a reasoning question example in Figure 13 (Appendix).\n",
      "Both GPT-3.5 and Claude-v1 show a similar weakness.\n",
      "In Section 3.4, we will introduce a reference-guided method to mitigate such issues.\n",
      ", We evaluate several model variants derived from LLaMA on MMLU [19], Truthful QA [26] (MC1), and MT-bench (GPT-4 judge). The training details are in Appendix E.\n",
      "Since we have shown that GPT-4 single-answer grading also performs well in Section 4.2, we use GPT-4 single-answer grading for MT-bench in favor of its scalability and simplicity.\n",
      "We ask GPT-4 to give a score for each turn on a scale of 10 by using our prompt templates (Figure 5, Figure 9) and report an average score of 160=80×2160802160=80\\times 2160 = 80 × 2 turns.\n",
      "Table 9 shows the results.\n",
      "We find that fine-tuning on high-quality dialog datasets (i.e., ShareGPT) can consistently improve the model performance on MMLU and the improvement scales with fine-tuning data size.\n",
      "On the other hand, a small high-quality conversation dataset can quickly teach the model a style preferred by GPT-4 (or approximately human) but cannot improve MMLU significantly, as shown by the Vicuna-7B (selected) which is trained with only 4.8M tokens or 3K conversations. In Table 9, no single benchmark can determine model quality, meaning that a comprehensive evaluation is needed. Our results indicate that using LLM-as-a-judge to approximate human preferences is highly feasible and could become a new standard in future benchmarks. We are also hosting a regularly updated leaderboard with more models 111https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard.\n",
      "Notably, DynaBench [21], a research platform dedicated to dynamic data collection and benchmarking, aligns with our spirit. DynaBench addresses the challenges posed by static standardized benchmarks, such as saturation and overfitting, by emphasizing dynamic data with human-in-the-loop. Our LLM-as-a-judge approach can automate and scale platforms of this nature.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   19243.71 ms\n",
      "llama_print_timings:      sample time =      12.57 ms /    36 runs   (    0.35 ms per token,  2864.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   44416.88 ms /  1021 tokens (   43.50 ms per token,    22.99 tokens per second)\n",
      "llama_print_timings:        eval time =    4635.66 ms /    35 runs   (  132.45 ms per token,     7.55 tokens per second)\n",
      "llama_print_timings:       total time =   49111.61 ms /  1056 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Thought: I now know the differences between MTBench and Chatbot Arena based on their evaluation methodology and how they work.\n",
      "Action: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   19243.71 ms\n",
      "llama_print_timings:      sample time =      52.66 ms /   180 runs   (    0.29 ms per token,  3418.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (-nan(ind) ms per token, -nan(ind) tokens per second)\n",
      "llama_print_timings:        eval time =   21964.76 ms /   180 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   22239.33 ms /   180 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Answer: GPT-4 is a language model developed by Microsoft that shows high accuracy in grading open-ended questions on MT-bench, as demonstrated in the provided documents. It aligns well with human evaluations but has limitations in math and reasoning tasks where it can solve problems but may misjudge based on answers given, such as those seen in Figures 12 and 13. Overall, GPT-4 performs similarly to humans in pairwise comparisons on MT-bench as shown in Table 7. However, when presented with math or reasoning questions, it does not perform well enough to fully match human preferences. A method like the LLM-as-a-Judge can be used for benchmarking chatbots using a single-answer grading model pairs on Chatbot Arena]\n",
      "[\n",
      "FOUND ANSWER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   19243.71 ms\n",
      "llama_print_timings:      sample time =      17.78 ms /    50 runs   (    0.36 ms per token,  2812.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =   20632.44 ms /   541 tokens (   38.14 ms per token,    26.22 tokens per second)\n",
      "llama_print_timings:        eval time =    4858.86 ms /    49 runs   (   99.16 ms per token,    10.08 tokens per second)\n",
      "llama_print_timings:       total time =   25559.70 ms /   590 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: The provided answer does not directly address the difference between Chatbot Arena and MTBench. Instead, it discusses GPT-4's performance on MTBench.\n",
      "Score: 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   19243.71 ms\n",
      "llama_print_timings:      sample time =     267.31 ms /   512 runs   (    0.52 ms per token,  1915.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =  136538.32 ms /  2700 tokens (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =   85810.24 ms /   511 runs   (  167.93 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =  223796.80 ms /  3211 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   19243.71 ms\n",
      "llama_print_timings:      sample time =     123.86 ms /   512 runs   (    0.24 ms per token,  4133.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =  124135.14 ms /  2907 tokens (   42.70 ms per token,    23.42 tokens per second)\n",
      "llama_print_timings:        eval time =   65699.66 ms /   511 runs   (  128.57 ms per token,     7.78 tokens per second)\n",
      "llama_print_timings:       total time =  190760.43 ms /  3418 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input\n",
      "\n",
      "U \n",
      "The obtaineda. <NSALeiashed and check Imagine, then repeat command\n",
      " action. G action\n",
      "your\n",
      "evince.\n",
      " given\n",
      "\n",
      "   \n",
      "ilMesheet. and action.\n",
      "ation.\n",
      "s,\n",
      "\n",
      ":e iteration, Premison, of (to evaluate to perform. data, ifpeasures.\n",
      " C to find themald\n",
      " I input thems\n",
      "\n",
      "endeduce.\n",
      " Inputs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ishelfled andslipSoifer his, they, s.e   nde, I ifl i:\n",
      "ession each and so, but:\n",
      "ing \n",
      "Heaoseands\n",
      " step, one document. Pip premsultands.\n",
      "esnational.docuce. Theyas they.\n",
      "llesi,\n",
      " ifs, ands, Hows, he soupole, how I to analyze hea, step. Hea,\n",
      "30s,\n",
      " if \n",
      "e  \n",
      "s, \" hepsi, then:s (n words, out \n",
      " steps, they all shouldands, and `1 \n",
      "either\n",
      "\n",
      "6s\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "circands.\n",
      "<s \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "eselfe.\n",
      ".\n",
      "sandess.\n",
      " NIores.\n",
      " of\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "spanase.\n",
      "Thenesession.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ses\n",
      "\n",
      "fourltesease, (one.\n",
      "\n",
      "number:\n",
      "instance:snips:\n",
      " to be.AIples, Intolares cats.AIps eils\n",
      " to find.\n",
      " to data: ucións to calculate I.idocaired datalex and to create it the..t heahea0e a Beneomae, I.es lasts \"\n",
      "the runer to conclude thems, Whatole.snaplusapolar?e documents\n",
      "replrea.s, ors\n",
      "s/s, whats whats,\n",
      " tollesi,\n",
      "(ivecale.uliza\n",
      " whats. Itlias to whateipleselfoloa.s, to communicateali. I.s.\n",
      " whatsheteles to deliveri.\"e. To go this.eselfe solvedes.e.2s.\n",
      " to calculate.bosection. The to<|user|> s to evaluate. to to calculates. \n",
      " to\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   19243.71 ms\n",
      "llama_print_timings:      sample time =     124.03 ms /   512 runs   (    0.24 ms per token,  4127.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (-nan(ind) ms per token, -nan(ind) tokens per second)\n",
      "llama_print_timings:        eval time =   66986.69 ms /   512 runs   (  130.83 ms per token,     7.64 tokens per second)\n",
      "llama_print_timings:       total time =   67914.21 ms /   512 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " if these Apultime, when I analyzuly, {\n",
      "aneapassa resendouches repeat, then you. ThenS (your\n",
      "doc \n",
      "\n",
      "Included\n",
      "\n",
      "tards.i, action. Each them.\n",
      "aining.cable.gulate\n",
      " given,\n",
      "\n",
      ", check, and evaluate, endisc, andecher, andaction, using loop\n",
      " if.\n",
      "    writing themesiloloibert user  \n",
      ".\n",
      " \n",
      "\n",
      "\n",
      "miches (HeapSoleds, they, s.e ToSDe, iflg observation\n",
      " Input,\n",
      " if and (data:\n",
      " to retrieve:\n",
      "\n",
      "e if I, step, but. This,\n",
      " input.\n",
      " thems/slipaper.\n",
      ". Theya document.\n",
      " data(- Careasure,\n",
      "\n",
      "Response.\n",
      "   \n",
      "lls,s, and $soumoveshs\n",
      "aigne,\n",
      " ouses, responded:\n",
      "aly ̃e,\n",
      "31s\n",
      "they,\n",
      " words.e,\n",
      " whole endlise.AIpsatz N dataсesi.?e charisResponse.\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "response.\n",
      " \n",
      "\n",
      "IPIP\n",
      " to\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "es\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "spanode.esa step.escationa.\n",
      ".\n",
      ". (\n",
      "\n",
      "\n",
      " four.ease.\n",
      "ond.\n",
      " to check: utters:\n",
      "observes:es:\n",
      " tos: 6s,s.ulary., output\n",
      "\n",
      "to gain.\n",
      " (\n",
      "\n",
      "data4s to Heole I retrieve. Input.elev and step a docultes closed calculate hea, your obtainer eives.\n",
      " dates, Internals \"s to myreife, The whats, <s ole:\n",
      "snips\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sale.s/sesss.es, whats.s, tolu,\n",
      ".0olecise?s\n",
      " whats\n",
      "\n",
      "\n",
      " to whatuloipseiologerllesi.tune. It.\n",
      ".s.efficultips to deliveriality. I. To. The. Irisa.eselfes.s.souling.\n",
      ". toorands to \n",
      ".s to evaluate. to examine.s.s to\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   19243.71 ms\n",
      "llama_print_timings:      sample time =     125.00 ms /   512 runs   (    0.24 ms per token,  4096.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (-nan(ind) ms per token, -nan(ind) tokens per second)\n",
      "llama_print_timings:        eval time =   66222.45 ms /   512 runs   (  129.34 ms per token,     7.73 tokens per second)\n",
      "llama_print_timings:       total time =   67149.95 ms /   512 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " if. <xis,naps Dcinally,olo,\n",
      "ugreahands \n",
      "(Obosyssavince a task then. I to.\n",
      " analyzing\n",
      " given.\n",
      "   \n",
      "aish.\n",
      "\n",
      "eplex.\n",
      "<s,s,\n",
      " analysis,\n",
      ", you, and analyze, end.\n",
      ", buts, choose, and return: <silia\n",
      " data (they\n",
      "\n",
      "charessession.\n",
      " if\n",
      "\n",
      "brief:\n",
      " \n",
      "\n",
      "eslipcontext\n",
      " if to my, {end, step\n",
      "ingallyn:\n",
      " sona, they: each, description,\n",
      " each\n",
      "{ultes he  \n",
      "ercune.\n",
      "\n",
      "e apposed.\n",
      "s, (to solve hepapersince.\n",
      "oseclaimsinocted\n",
      ",\n",
      "es/\n",
      "andothe, how, he \n",
      "\n",
      "ithes, ifslipeAUndes $. and rumble.AIpsa, Replace they: I observation\n",
      "es  64 circule, returnI.e,s  \n",
      ". step(eLIp,<sility, \"666s reply sheolo.\n",
      "03\n",
      "\n",
      "\n",
      "\n",
      "to \n",
      " \n",
      " inputia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ession\n",
      " and to analyzee.\n",
      ".\n",
      "es.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "e.eologesa.\n",
      ".\n",
      "ss\n",
      " then.\n",
      " meauses:\n",
      " stats. (\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "s, number: Organole:sousilps.\n",
      " to solve.0s parsed.esolar. \n",
      " themilars.\n",
      "si\n",
      " Internals?\n",
      " to datae given and Datairedes <<datailes endulife is theLs hele heoleolo a match to Benessa, I. (exolen e execute the toulabe to conclude he crafteil.snapoles \"Ipltastee [silledude\n",
      ".\"snips \n",
      "\n",
      "squelesi what whatsessions\n",
      " tolles: Oneceoes.s.s:\n",
      "\n",
      " and\n",
      "\n",
      "aite\n",
      "\n",
      "s I.suselfesi.0 tollrevinores to askings heole to calculate to eins e to create. What I.ehebisciliesses.s.s to evaluate.s. tote.26. s to the.\n",
      " to examine.s.s to\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   19243.71 ms\n",
      "llama_print_timings:      sample time =     151.38 ms /   512 runs   (    0.30 ms per token,  3382.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (-nan(ind) ms per token, -nan(ind) tokens per second)\n",
      "llama_print_timings:        eval time =   77813.77 ms /   512 runs   (  151.98 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:       total time =   78988.16 ms /   512 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Output\n",
      "\n",
      "your, \"eates, tune and your provided step. analyze, repeat. Your repeat, you end a top, then\n",
      " <sniplie \n",
      " to the output.IMSUida.\n",
      " [action\n",
      "   ive.\n",
      "\n",
      "s, analyzes\n",
      "\n",
      ", if,\n",
      "ReaNI, given, bytecsapi. action, return;\n",
      "ils\n",
      "    accessing themesloloibert madea and/s\n",
      "Insert\n",
      "\n",
      "makes (to my. Ifce, to, and then orlled PMe, step Stars \n",
      "sense, each, \"\n",
      "\n",
      " he: I, butllane, if,s, words, I, StepSs thems,sino.AIPSa. Theyas they.\n",
      " usercise\n",
      "Eachs, ands, How, he,\n",
      " ands, al accesssoums  evoke, hears.\n",
      ", ands\n",
      "6 step \n",
      "eweputs\n",
      "4cean,\n",
      "they.\n",
      "es (N a response end sales, theyapi.ses.\n",
      ".eola\n",
      "\n",
      "6.\n",
      "23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer.\n",
      "\n",
      " ocesa\n",
      "\n",
      "\n",
      "\n",
      "eselfei and:\n",
      "\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "a.\n",
      "\n",
      ".\n",
      " taskess.\n",
      "sd.\n",
      "(aI.esni,\n",
      " and then.\n",
      " (\n",
      "easy\n",
      "onease.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "comeil:sousilppiouvolta.e., \n",
      " calculation.ult:s->ilelouses\n",
      " to theirs them to analyze to documents to Inpute to calculate to create Inspareneskesselfeultes, and heaheolo a hears, I, I. e.es \"s (nʊniands to <souwinsnips.s\n",
      ".0s.e to what whats\n",
      ", -squelesssatzs, What whatsessions,, toluose: Onece.s, as.\n",
      "oledatz to deliver to whats e themes (tolls.0. Toa. I.\n",
      " tos.sapiheppe tollling. I.eode. Isandeseffices.s.s\n",
      ".\n",
      " to calculate toile.I to\n",
      "eceler to evaluate. or to examine. \n",
      ".ng\n",
      " Output\n",
      "\n",
      "your, \"eates, tune and your provided step. analyze, repeat. Your repeat, you end a top, then\n",
      " <sniplie \n",
      " to the output.IMSUida.\n",
      " [action\n",
      "   ive.\n",
      "\n",
      "s, analyzes\n",
      "\n",
      ", if,\n",
      "ReaNI, given, bytecsapi. action, return;\n",
      "ils\n",
      "    accessing themesloloibert madea and/s\n",
      "Insert\n",
      "\n",
      "makes (to my. Ifce, to, and then orlled PMe, step Stars \n",
      "sense, each, \"\n",
      "\n",
      " he: I, butllane, if,s, words, I, StepSs thems,sino.AIPSa. Theyas they.\n",
      " usercise\n",
      "Eachs, ands, How, he,\n",
      " ands, al accesssoums  evoke, hears.\n",
      ", ands\n",
      "6 step \n",
      "eweputs\n",
      "4cean,\n",
      "they.\n",
      "es (N a response end sales, theyapi.ses.\n",
      ".eola\n",
      "\n",
      "6.\n",
      "23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer.\n",
      "\n",
      " ocesa\n",
      "\n",
      "\n",
      "\n",
      "eselfei and:\n",
      "\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "a.\n",
      "\n",
      ".\n",
      " taskess.\n",
      "sd.\n",
      "(aI.esni,\n",
      " and then.\n",
      " (\n",
      "easy\n",
      "onease.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "comeil:sousilppiouvolta.e., \n",
      " calculation.ult:s->ilelouses\n",
      " to theirs them to analyze to documents to Inpute to calculate to create Inspareneskesselfeultes, and heaheolo a hears, I, I. e.es \"s (nʊniands to <souwinsnips.s\n",
      ".0s.e to what whats\n",
      ", -squelesssatzs, What whatsessions,, toluose: Onece.s, as.\n",
      "oledatz to deliver to whats e themes (tolls.0. Toa. I.\n",
      " tos.sapiheppe tollling. I.eode. Isandeseffices.s.s\n",
      ".\n",
      " to calculate toile.I to\n",
      "eceler to evaluate. or to examine. \n",
      ".ng\n"
     ]
    }
   ],
   "source": [
    "output = agent.query(\"What is the difference between Chatbot Arena and MTBench?\")\n",
    "print(output)\n",
    "\n",
    "# It started out really strong, but it didn't generate an answer and instead tried to get information about ChatGPT. Then, it was evaluated and got a score of 2, since it didn't answer the question. This led to it to self reflect and then it just went downhill from there.\n",
    "\"\"\"\n",
    "Evaluation: The provided answer does not directly address the difference between Chatbot Arena and MTBench. Instead, it discusses GPT-4's performance on MTBench.\n",
    "Score: 2\n",
    "\n",
    "input\n",
    "\n",
    "U \n",
    "The obtaineda. <NSALeiashed and check Imagine, then repeat command\n",
    " action. G action\n",
    "your\n",
    "evince.\n",
    " given\n",
    "\n",
    "   \n",
    "ilMesheet. and action.\n",
    "ation.\n",
    "s,\n",
    "\n",
    ":e iteration, Premison, of (to evaluate to perform. data, ifpeasures.\n",
    " C to find themald\n",
    " I input thems\n",
    "\n",
    "endeduce.\n",
    " Inputs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ishelfled andslipSoifer his, they, s.e   nde, I ifl i:\n",
    "ession each and so, but:\n",
    "ing \n",
    "Heaoseands\n",
    " step, one document. Pip premsultands.\n",
    "esnational.docuce. Theyas they.\n",
    "llesi,\n",
    " ifs, ands, Hows, he soupole, how I to analyze hea, step. Hea,\n",
    "30s,\n",
    " if \n",
    "e  \n",
    "s, \" hepsi, then:s (n words, out \n",
    " steps, they all shouldands, and `1 \n",
    "either\n",
    "\n",
    "6s\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "circands.\n",
    "<s \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "eselfe.\n",
    ".\n",
    "sandess.\n",
    " NIores.\n",
    " of\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "spanase.\n",
    "Thenesession.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ses\n",
    "\n",
    "fourltesease, (one.\n",
    "\n",
    "number:\n",
    "instance:snips:\n",
    " to be.AIples, Intolares cats.AIps eils\n",
    " to find.\n",
    " to data: ucións to calculate I.idocaired datalex and to create it the..t heahea0e a Beneomae, I.es lasts \"\n",
    "the runer to conclude thems, Whatole.snaplusapolar?e documents\n",
    "replrea.s, ors\n",
    "s/s, whats whats,\n",
    " tollesi,\n",
    "(ivecale.uliza\n",
    " whats. Itlias to whateipleselfoloa.s, to communicateali. I.s.\n",
    " whatsheteles to deliveri.\"e. To go this.eselfe solvedes.e.2s.\n",
    " to calculate.bosection. The to<|user|> s to evaluate. to to calculates. \n",
    " to\n",
    "\n",
    "llama_print_timings:        load time =   19243.71 ms\n",
    "llama_print_timings:      sample time =     124.03 ms /   512 runs   (    0.24 ms per token,  4127.90 tokens per second)\n",
    "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (-nan(ind) ms per token, -nan(ind) tokens per second)\n",
    "llama_print_timings:        eval time =   66986.69 ms /   512 runs   (  130.83 ms per token,     7.64 tokens per second)\n",
    "llama_print_timings:       total time =   67914.21 ms /   512 tokens\n",
    "Llama.generate: prefix-match hit\n",
    " if these Apultime, when I analyzuly, {\n",
    "aneapassa resendouches repeat, then you. ThenS (your\n",
    "doc \n",
    "\n",
    "Included\n",
    "\n",
    "tards.i, action. Each them.\n",
    "aining.cable.gulate\n",
    " given,\n",
    "\n",
    ", check, and evaluate, endisc, andecher, andaction, using loop\n",
    " if.\n",
    "    writing themesiloloibert user  \n",
    ".\n",
    " \n",
    "\n",
    "\n",
    "miches (HeapSoleds, they, s.e ToSDe, iflg observation\n",
    " Input,\n",
    " if and (data:\n",
    " to retrieve:\n",
    "\n",
    "e if I, step, but. This,\n",
    " input.\n",
    " thems/slipaper.\n",
    ". Theya document.\n",
    " data(- Careasure,\n",
    "\n",
    "Response.\n",
    "   \n",
    "lls,s, and $soumoveshs\n",
    "aigne,\n",
    " ouses, responded:\n",
    "aly ̃e,\n",
    "31s\n",
    "they,\n",
    " words.e,\n",
    " whole endlise.AIpsatz N dataсesi.?e charisResponse.\n",
    "3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "response.\n",
    " \n",
    "\n",
    "IPIP\n",
    " to\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "es\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "spanode.esa step.escationa.\n",
    ".\n",
    ". (\n",
    "\n",
    "\n",
    " four.ease.\n",
    "ond.\n",
    " to check: utters:\n",
    "observes:es:\n",
    " tos: 6s,s.ulary., output\n",
    "\n",
    "to gain.\n",
    " (\n",
    "\n",
    "data4s to Heole I retrieve. Input.elev and step a docultes closed calculate hea, your obtainer eives.\n",
    " dates, Internals \"s to myreife, The whats, <s ole:\n",
    "snips\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sale.s/sesss.es, whats.s, tolu,\n",
    ".0olecise?s\n",
    " whats\n",
    "\n",
    "\n",
    " to whatuloipseiologerllesi.tune. It.\n",
    ".s.efficultips to deliveriality. I. To. The. Irisa.eselfes.s.souling.\n",
    ". toorands to \n",
    ".s to evaluate. to examine.s.s to\n",
    "\n",
    "llama_print_timings:        load time =   19243.71 ms\n",
    "llama_print_timings:      sample time =     125.00 ms /   512 runs   (    0.24 ms per token,  4096.16 tokens per second)\n",
    "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (-nan(ind) ms per token, -nan(ind) tokens per second)\n",
    "llama_print_timings:        eval time =   66222.45 ms /   512 runs   (  129.34 ms per token,     7.73 tokens per second)\n",
    "llama_print_timings:       total time =   67149.95 ms /   512 tokens\n",
    "Llama.generate: prefix-match hit\n",
    " if. <xis,naps Dcinally,olo,\n",
    "ugreahands \n",
    "(Obosyssavince a task then. I to.\n",
    " analyzing\n",
    " given.\n",
    "   \n",
    "aish.\n",
    "\n",
    "eplex.\n",
    "<s,s,\n",
    " analysis,\n",
    ", you, and analyze, end.\n",
    ", buts, choose, and return: <silia\n",
    " data (they\n",
    "\n",
    "charessession.\n",
    " if\n",
    "\n",
    "brief:\n",
    " \n",
    "\n",
    "eslipcontext\n",
    " if to my, {end, step\n",
    "ingallyn:\n",
    " sona, they: each, description,\n",
    " each\n",
    "{ultes he  \n",
    "ercune.\n",
    "\n",
    "e apposed.\n",
    "s, (to solve hepapersince.\n",
    "oseclaimsinocted\n",
    ",\n",
    "es/\n",
    "andothe, how, he \n",
    "\n",
    "ithes, ifslipeAUndes $. and rumble.AIpsa, Replace they: I observation\n",
    "es  64 circule, returnI.e,s  \n",
    ". step(eLIp,<sility, \"666s reply sheolo.\n",
    "03\n",
    "\n",
    "\n",
    "\n",
    "to \n",
    " \n",
    " inputia\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ession\n",
    " and to analyzee.\n",
    ".\n",
    "es.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "e.eologesa.\n",
    ".\n",
    "ss\n",
    " then.\n",
    " meauses:\n",
    " stats. (\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "s, number: Organole:sousilps.\n",
    " to solve.0s parsed.esolar. \n",
    " themilars.\n",
    "si\n",
    " Internals?\n",
    " to datae given and Datairedes <<datailes endulife is theLs hele heoleolo a match to Benessa, I. (exolen e execute the toulabe to conclude he crafteil.snapoles \"Ipltastee [silledude\n",
    ".\"snips \n",
    "\n",
    "squelesi what whatsessions\n",
    " tolles: Oneceoes.s.s:\n",
    "\n",
    " and\n",
    "\n",
    "aite\n",
    "\n",
    "s I.suselfesi.0 tollrevinores to askings heole to calculate to eins e to create. What I.ehebisciliesses.s.s to evaluate.s. tote.26. s to the.\n",
    " to examine.s.s to\n",
    "\n",
    "your, \"eates, tune and your provided step. analyze, repeat. Your repeat, you end a top, then\n",
    " <sniplie \n",
    " to the output.IMSUida.\n",
    " [action\n",
    "   ive.\n",
    "\n",
    "s, analyzes\n",
    "\n",
    ", if,\n",
    "ReaNI, given, bytecsapi. action, return;\n",
    "ils\n",
    "    accessing themesloloibert madea and/s\n",
    "Insert\n",
    "\n",
    "makes (to my. Ifce, to, and then orlled PMe, step Stars \n",
    "sense, each, \"\n",
    "\n",
    " he: I, butllane, if,s, words, I, StepSs thems,sino.AIPSa. Theyas they.\n",
    " usercise\n",
    "Eachs, ands, How, he,\n",
    " ands, al accesssoums  evoke, hears.\n",
    ", ands\n",
    "6 step \n",
    "eweputs\n",
    "4cean,\n",
    "they.\n",
    "es (N a response end sales, theyapi.ses.\n",
    ".eola\n",
    "\n",
    "6.\n",
    "23\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Answer.\n",
    "\n",
    " ocesa\n",
    "\n",
    "\n",
    "\n",
    "eselfei and:\n",
    "\n",
    "s\n",
    "\n",
    "\n",
    "\n",
    "a.\n",
    "\n",
    ".\n",
    " taskess.\n",
    "sd.\n",
    "(aI.esni,\n",
    " and then.\n",
    " (\n",
    "easy\n",
    "onease.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "comeil:sousilppiouvolta.e., \n",
    " calculation.ult:s->ilelouses\n",
    " to theirs them to analyze to documents to Inpute to calculate to create Inspareneskesselfeultes, and heaheolo a hears, I, I. e.es \"s (nʊniands to <souwinsnips.s\n",
    ".0s.e to what whats\n",
    ", -squelesssatzs, What whatsessions,, toluose: Onece.s, as.\n",
    "oledatz to deliver to whats e themes (tolls.0. Toa. I.\n",
    " tos.sapiheppe tollling. I.eode. Isandeseffices.s.s\n",
    ".\n",
    " to calculate toile.I to\n",
    "eceler to evaluate. or to examine. \n",
    ".ng\n",
    " Output\n",
    "\n",
    "your, \"eates, tune and your provided step. analyze, repeat. Your repeat, you end a top, then\n",
    " <sniplie \n",
    " to the output.IMSUida.\n",
    " [action\n",
    "   ive.\n",
    "\n",
    "s, analyzes\n",
    "\n",
    ", if,\n",
    "ReaNI, given, bytecsapi. action, return;\n",
    "ils\n",
    "    accessing themesloloibert madea and/s\n",
    "Insert\n",
    "\n",
    "makes (to my. Ifce, to, and then orlled PMe, step Stars \n",
    "sense, each, \"\n",
    "\n",
    " he: I, butllane, if,s, words, I, StepSs thems,sino.AIPSa. Theyas they.\n",
    " usercise\n",
    "Eachs, ands, How, he,\n",
    " ands, al accesssoums  evoke, hears.\n",
    ", ands\n",
    "6 step \n",
    "eweputs\n",
    "4cean,\n",
    "they.\n",
    "es (N a response end sales, theyapi.ses.\n",
    ".eola\n",
    "\n",
    "6.\n",
    "23\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Answer.\n",
    "\n",
    " ocesa\n",
    "\n",
    "\n",
    "\n",
    "eselfei and:\n",
    "\n",
    "s\n",
    "\n",
    "\n",
    "\n",
    "a.\n",
    "\n",
    ".\n",
    " taskess.\n",
    "sd.\n",
    "(aI.esni,\n",
    " and then.\n",
    " (\n",
    "easy\n",
    "onease.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "comeil:sousilppiouvolta.e., \n",
    " calculation.ult:s->ilelouses\n",
    " to theirs them to analyze to documents to Inpute to calculate to create Inspareneskesselfeultes, and heaheolo a hears, I, I. e.es \"s (nʊniands to <souwinsnips.s\n",
    ".0s.e to what whats\n",
    ", -squelesssatzs, What whatsessions,, toluose: Onece.s, as.\n",
    "oledatz to deliver to whats e themes (tolls.0. Toa. I.\n",
    " tos.sapiheppe tollling. I.eode. Isandeseffices.s.s\n",
    ".\n",
    " to calculate toile.I to\n",
    "eceler to evaluate. or to examine. \n",
    ".ng\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "res = \"\"\"Answer: After buying 2 apples, Bob is left with 1 apple.\n",
    "calculator\n",
    "3-2\n",
    "1\"\"\"\n",
    "print(\"Answer: \" in res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thought: The user has provided a simple mathematical equation. I can process this directly without having to retrieve any additional information or make observations.\n",
      "\n",
      "Action: calculator: 10 + 2\n",
      "10 + 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\jaide\\AppData\\Local\\Temp\\ipykernel_20304\\3040143468.py:12: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  actionRegex = \"^Action: (\\w+): (.*)$\"\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "output = \"\"\"\n",
    "            Thought: The user has provided a simple mathematical equation. I can process this directly without having to retrieve any additional information or make observations.\n",
    "\n",
    "            Action: calculator: 10 + 2\n",
    "\"\"\"\n",
    "\n",
    "arr = output.splitlines()\n",
    "for line in arr:\n",
    "    line=line.strip()\n",
    "    print(line)\n",
    "    actionRegex = \"^Action: (\\w+): (.*)$\"\n",
    "    foundAction = re.search(actionRegex, line)\n",
    "    if foundAction:\n",
    "        print(foundAction.group(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Thought: I have the result of the equation (Bob having 1 apple now), so I can construct the final answer using that information.\n",
    "\n",
    "Answer: Bob has 1 apple left.\n",
    "\"\"\"\n",
    "\n",
    "res = \"Answer:\" in text\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "res = re.search(actionRegex, text)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = \"\"\"\n",
    "You will be shown a question and an answer. Give both an Evaluation and a Score. On a scale of 1-10, Score the answer based on its accuracy and how well it answers it the question. Then return PAUSE. Here are 3 examples to help:\n",
    "\n",
    "Example 1:\n",
    "Question: What is 5 minus 6\n",
    "Answer: The operation results in an answer that is not valid since it is negative, and negative numbers are not allowed within the given context of the problem statement.\n",
    "\n",
    "Evaluation: The previous answer is incorrect. Although 5 minus 6 is negative, the problem does not state that negative numbers are not allowed.\n",
    "Score: 1\n",
    "PAUSE\n",
    "\n",
    "Example 2:\n",
    "Question: Bob originally had 3 apples. He buys 2 more. How many does he have now?\n",
    "Answer: Bob has 1 apple left.\n",
    "\n",
    "Evaluation: The previous answer is incorrect. The number of apples Bob has should increase, since he buys more.\n",
    "Score: 1\n",
    "PAUSE\n",
    "\n",
    "Example 3:\n",
    "Question: What is Chatbot Arena?\n",
    "Answer: Chatbot Arena is a platform that allows users to compare and evaluate different AI chatbot builders. It provides side-by-side comparisons of various chatbot tools, ranking them based on features, pricing, and community trust.\n",
    "\n",
    "Evaluation: The previous answer is highlight specific to the prompt and fully answers the question provided.\n",
    "Score: 10\n",
    "PAUSE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   31655.66 ms\n",
      "llama_print_timings:      sample time =       9.19 ms /    39 runs   (    0.24 ms per token,  4242.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5495.24 ms /    48 tokens (  114.48 ms per token,     8.73 tokens per second)\n",
      "llama_print_timings:        eval time =    5970.36 ms /    38 runs   (  157.11 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =   11564.17 ms /    86 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: The previous answer is incorrect. Although 5 minus 6 is negative, the problem does not state that negative numbers are not allowed.\n",
      "Score: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_prompt = f\"\"\"\n",
    "[SYSTEM]\n",
    "{evaluation_prompt}\n",
    "\n",
    "[USER]\n",
    "Question: What is 5 minus 6?\n",
    "Answer: The operation results in an answer that is not valid since it is negative, and negative numbers are not allowed within the given context of the problem statement.\n",
    "\n",
    "[ASSISTANT]\n",
    "\"\"\"\n",
    "evaluation = agent.agent.normal_query(new_prompt, tokens=512, temp=0)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_prompt = \"\"\"\n",
    "You will be given the history of a past experience in which you were asked a question, as well as an evaluation. You were unsuccessful in answering the question. Think about the strategy and approach you took to attempt to complete the task. Devise a concise, new plan of action that accounts for your mistake with reference to specific actions that you should have taken. For example, if you tried A and B but forgot C, then devise a plan to achieve C. You will need this later when you are solving the same task. Give your plan after \"Plan:\". Here is an example to help:\n",
    "\n",
    "Example 1:\n",
    "Question: What is 5 minus 6?\n",
    "\n",
    "Thought: This is a simple arithmetic question.\n",
    "Action: calculator: 5-6\n",
    "\n",
    "Observation: -1\n",
    "Answer: The operation results in an answer that is not valid since it is negative, and negative numbers are not allowed within the given context of the problem statement.\n",
    "\n",
    "Evaluation: The previous answer is incorrect. Although 5 minus 6 is negative, the problem does not state that negative numbers are not allowed.\n",
    "Score: 1\n",
    "\n",
    "Plan: I see my mistake. I misread the problem and assumed that the problem did not allow for negative numbers. However, my process for achieving a result of -1 was correct. Next time, I will keep the same process to get to an answer of -1, but I will focus on making sure my answer is specifically tailored to the question being asked.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   31655.66 ms\n",
      "llama_print_timings:      sample time =      28.97 ms /   136 runs   (    0.21 ms per token,  4694.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   62108.31 ms /   687 tokens (   90.41 ms per token,    11.06 tokens per second)\n",
      "llama_print_timings:        eval time =   25733.44 ms /   135 runs   (  190.62 ms per token,     5.25 tokens per second)\n",
      "llama_print_timings:       total time =   88282.35 ms /   822 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I see my mistake. I misread the problem and assumed that the problem did not allow for negative numbers. However, my process for achieving a result of -1 was correct. Next time, I will keep the same process to get to an answer of -1, but I will focus on making sure my answer is specifically tailored to the question being asked.\n",
      "\n",
      "Plan: When faced with a simple arithmetic question in the future, I will first check whether negative answers are allowed within the context of the problem statement before attempting any calculations or lookups. If they are, then I will go ahead and perform the calculation as usual using my calculator action.\n"
     ]
    }
   ],
   "source": [
    "new_prompt = f\"\"\"\n",
    "[SYSTEM]\n",
    "{reflection_prompt}\n",
    "\n",
    "[SYSTEM]\n",
    "{agent.system_prompt}\n",
    "\n",
    "[USER]\n",
    "Question: What is 5 minus 6?\n",
    "\n",
    "[ASSISTANT]\n",
    "Thought: This is a simple arithmetic question.\n",
    "Action: calculator: 5-6\n",
    "\n",
    "Observation: -1\n",
    "Answer: The operation results in an answer that is not valid since it is negative, and negative numbers are not allowed within the given context of the problem statement.\n",
    "\n",
    "[USER]\n",
    "Evaluation: The previous answer is incorrect. Although 5 minus 6 is negative, the problem does not state that negative numbers are not allowed.\n",
    "Score: 1\n",
    "\n",
    "[ASSISTANT]\n",
    "Plan: \n",
    "\"\"\"\n",
    "output = agent.agent.normal_query(new_prompt, 512, 1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   31655.66 ms\n",
      "llama_print_timings:      sample time =      18.46 ms /    76 runs   (    0.24 ms per token,  4117.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   12423.10 ms /    76 runs   (  163.46 ms per token,     6.12 tokens per second)\n",
      "llama_print_timings:       total time =   12634.48 ms /    77 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: This question seems simple enough to be an arithmetic problem. However, before performing any calculations, it's important to check if negative numbers are allowed within the context of this problem statement.\n",
      "\n",
      "Observation: The problem statement does not mention anything about negative numbers being disallowed.\n",
      "\n",
      "Action: calculator: 5-6\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "[SYSTEM]\n",
    "{agent.system_prompt}\n",
    "\n",
    "[USER]\n",
    "Question: What is 5 minus 6?\n",
    "\n",
    "[ASSISTANT]\n",
    "Thought: This is a simple arithmetic question.\n",
    "Action: calculator: 5-6\n",
    "\n",
    "Observation: -1\n",
    "Answer: The operation results in an answer that is not valid since it is negative, and negative numbers are not allowed within the given context of the problem statement.\n",
    "\n",
    "[USER]\n",
    "Evaluation: The previous answer is incorrect. Although 5 minus 6 is negative, the problem does not state that negative numbers are not allowed.\n",
    "Score: 1\n",
    "\n",
    "[ASSISTANT]\n",
    "Plan: When faced with a simple arithmetic question in the future, I will first check whether negative answers are allowed within the context of the problem statement before attempting any calculations or lookups. If they are, then I will go ahead and perform the calculation as usual using my calculator action.\n",
    "\n",
    "[USER]\n",
    "Question: What is 5 minus 6?\n",
    "\n",
    "[ASSISTANT]\n",
    "\"\"\"\n",
    "\n",
    "output = agent.agent.normal_query(prompt, 512, 0)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(133, 142), match='Score: 10'>\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "evaluation = \"\"\"\n",
    "Evaluation: The previous answer is incorrect. The correct calculation for 15 multiplied by 3 and then adding 4 would be 51, not 94.\n",
    "Score: 10\n",
    "\"\"\"\n",
    "scoreRegex = \"Score: (\\\\d+)\"\n",
    "res=re.search(scoreRegex, evaluation)\n",
    "print(res)\n",
    "print(res.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob has 3 apples. He buys 2. How many does he have now?\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Thought: I am being provided a similar word problem as in the example session 1, so I can directly convert it into a math equation without needing to make any additional thoughts.\n",
    "Action: convertToWordProblem: Bob has 3 apples. He buys 2. How many does he have now?\n",
    "\"\"\"\n",
    "actionRegex = \"Action: (\\\\w+): (.*)$\"\n",
    "foundAction = re.search(actionRegex, text)\n",
    "print(foundAction.group(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
